{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "450f79e0-1173-4f4f-a31a-418ee41c605e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "# import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2061b16d-c694-407d-ad6f-b90928cddb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datapreprocess\n",
    "Greek = pd.read_csv(r'Greek.csv')\n",
    "inforce = pd.read_csv('inforce.csv')\n",
    "df = pd.merge(Greek, inforce)\n",
    "age = (df['currentDate']- df['birthDate'])/365\n",
    "ttm = (df['matDate']- df['currentDate'])/365\n",
    "df = df[['recordID','gender','gmwbBalance','productType','gbAmt','FundValue1', 'FundValue2', 'FundValue3', 'FundValue4', 'FundValue5',\n",
    "       'FundValue6', 'FundValue7', 'FundValue8', 'FundValue9', 'FundValue10', 'fmv']]\n",
    "df[\"age\"] = age\n",
    "df['ttm'] = ttm\n",
    "df = df[['recordID','gender','gmwbBalance','productType','gbAmt','FundValue1', 'FundValue2', 'FundValue3', 'FundValue4', 'FundValue5',\n",
    "       'FundValue6', 'FundValue7', 'FundValue8', 'FundValue9', 'FundValue10', 'fmv','age','ttm']]\n",
    "dummy = pd.get_dummies(df[['recordID','productType','gender']], drop_first=True)\n",
    "\n",
    "df = pd.merge(df, dummy)\n",
    "df = df.drop(['productType','gender','recordID'], axis=1)\n",
    "\n",
    "colname = ['gmwbBalance', 'gbAmt', 'FundValue1', 'FundValue2', 'FundValue3',\n",
    "       'FundValue4', 'FundValue5', 'FundValue6', 'FundValue7', 'FundValue8',\n",
    "       'FundValue9', 'FundValue10']\n",
    "\n",
    "# norm = preprocessing.normalize(df[colname])\n",
    "# df[colname] = norm\n",
    "df[colname] = (df[colname]-df[colname].mean(0))/(df[colname].max(0)-df[colname].min(0))\n",
    "df['fmv'] = df['fmv']/1000\n",
    "import random\n",
    "random.seed(10)\n",
    "df = df.sample(frac = 1, replace = False)\n",
    "df.to_csv('data.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "993a3328-a857-4f8b-af85-de9955b0b78f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting OLS.py\n"
     ]
    }
   ],
   "source": [
    "%%file OLS.py\n",
    "#!/usr/bin/env python3\n",
    "from mpi4py import MPI\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys\n",
    "import time\n",
    "import statsmodels.api as sm\n",
    "\n",
    "def OLS(comm,rank, size):\n",
    "    if rank == 0:\n",
    "        data = pd.read_csv(\"data.csv\")\n",
    "        split_rate = 0.9\n",
    "        Train = data.iloc[:int(data.shape[0]*split_rate),:]\n",
    "        Test = data.iloc[int(data.shape[0]*split_rate):,:]\n",
    "\n",
    "    else:\n",
    "        # data = None\n",
    "        Train = None\n",
    "        Test = None\n",
    "    # data = comm.bcast(data,root = 0)\n",
    "    Train = comm.bcast(Train,root = 0)\n",
    "    Test = comm.bcast(Test,root = 0)\n",
    "\n",
    "    y_test = Test['fmv']\n",
    "    X_test = Test.drop(['fmv'],axis = 1)\n",
    "    X_test = sm.add_constant(X_test)\n",
    "    y_test_pre_list = []\n",
    "    error_model_list = []\n",
    "    for i in range(2):\n",
    "        Train_sample = Train.sample(frac = 1, replace = True)\n",
    "        y_train_sample = Train_sample['fmv']\n",
    "        X_train_sample = Train_sample.drop(['fmv'],axis = 1)\n",
    "        X_train_sample = sm.add_constant(X_train_sample)\n",
    "        \n",
    "        model = sm.OLS(y_train_sample,X_train_sample).fit()\n",
    "        \n",
    "        y_train_sample_pre = model.predict(X_train_sample)\n",
    "        error_model = y_train_sample-y_train_sample_pre\n",
    "        error_model_list.append(error_model)\n",
    "        y_test_pre = model.predict(X_test)\n",
    "        y_test_pre_list.append(y_test_pre)\n",
    "        print('The rank',rank,'iteration',i)\n",
    "    error_model_list = np.array(error_model_list)\n",
    "    y_test_pre_list = np.array(y_test_pre_list)\n",
    "    y_test_pre_l = np.empty((size,) + y_test_pre_list.shape)\n",
    "    error_l = np.empty((size,) + error_model_list.shape)\n",
    "    comm.Gatherv(error_model_list, error_l,root=0)\n",
    "    comm.Gatherv(y_test_pre_list,y_test_pre_l, root=0)\n",
    "    if rank == 0:\n",
    "        y_test_pre_list_ = np.transpose(y_test_pre_l.reshape(y_test_pre_l.shape[0]*y_test_pre_l.shape[1],y_test_pre_l.shape[2]))\n",
    "        print(y_test_pre_list_.shape)\n",
    "        error_model_list_ = np.transpose(error_l.reshape(error_l.shape[0]*error_l.shape[1],error_l.shape[2]))\n",
    "        error_random = np.random.choice(np.array(error_model_list_).flatten(),(y_test_pre_list_.shape))\n",
    "        y_test_revise_list   = y_test_pre_list_ +   error_random\n",
    "        Left_list = np.quantile(np.transpose(y_test_revise_list),0.025,axis = 0)\n",
    "        # print(Left_list.shape)\n",
    "        Right_list = np.quantile(np.transpose(y_test_revise_list),0.975,axis = 0)\n",
    "        # print(Right_list.shape)\n",
    "        Bool_list = (y_test >= Left_list) & (y_test< Right_list)\n",
    "\n",
    "        diff = Right_list-Left_list\n",
    "        results_10_1000 = pd.DataFrame([])\n",
    "        results_10_1000['Left_list'] = np.array(Left_list)\n",
    "        results_10_1000['Right_list'] = np.array(Right_list)\n",
    "        results_10_1000['Bool_list'] = np.array(Bool_list)\n",
    "        results_10_1000['width'] = np.array(diff)\n",
    "        results_10_1000['test'] = np.array(Test['fmv'].copy())\n",
    "        pd.DataFrame(results_10_1000).to_csv('./result/results_10_1000.csv',index = False)\n",
    "        print(f\"accuracy: {Bool_list.mean():.6f}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # name = MPI.Get_processor_name()\n",
    "    comm = MPI.COMM_WORLD\n",
    "    rank = comm.Get_rank()\n",
    "    size = comm.Get_size()\n",
    "    t = time.time()\n",
    "    OLS(comm,rank, size)\n",
    "    print(time.time()-t)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "463d94ce-e14f-48eb-9a06-df3d877590c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Huber.py\n"
     ]
    }
   ],
   "source": [
    "%%file Huber.py\n",
    "#!/usr/bin/env python\n",
    "from mpi4py import MPI\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import HuberRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import sys\n",
    "\n",
    "\n",
    "def Huber(comm,rank, size):\n",
    "    if rank == 0:\n",
    "        data = pd.read_csv(\"data.csv\")\n",
    "        split_rate = 0.9\n",
    "        Train = data.iloc[:int(data.shape[0]*split_rate),:]\n",
    "        Test = data.iloc[int(data.shape[0]*split_rate):,:]\n",
    "\n",
    "    else:\n",
    "        # data = None\n",
    "        Train = None\n",
    "        Test = None\n",
    "    # data = comm.bcast(data,root = 0)\n",
    "    Train = comm.bcast(Train,root = 0)\n",
    "    Test = comm.bcast(Test,root = 0)\n",
    "\n",
    "\n",
    "    y_test = Test['fmv']\n",
    "    X_test = Test.drop(['fmv'],axis = 1)\n",
    "    print(rank)\n",
    "    y_test_pre_list = []\n",
    "    error_model_list = []\n",
    "    for i in range(5):\n",
    "        Train_sample = Train.sample(frac = 1, replace = True)\n",
    "        y_train_sample = Train_sample['fmv']\n",
    "        X_train_sample = Train_sample.drop(['fmv'],axis = 1)\n",
    "\n",
    "        model = HuberRegressor()\n",
    "        model.fit(X_train_sample,y_train_sample)\n",
    "\n",
    "        y_train_sample_pre = model.predict(X_train_sample)\n",
    "        error_model = y_train_sample-y_train_sample_pre\n",
    "        error_model_list.append(error_model)\n",
    "        y_test_pre = model.predict(X_test)\n",
    "        y_test_pre_list.append(y_test_pre)\n",
    "        print('The rank',rank,'iteration',i)\n",
    "    error_model_list = np.array(error_model_list)\n",
    "    y_test_pre_list = np.array(y_test_pre_list)\n",
    "    y_test_pre_l = np.empty((size,) + y_test_pre_list.shape)\n",
    "    error_l = np.empty((size,) + error_model_list.shape)\n",
    "    comm.Gatherv(error_model_list, error_l,root=0)\n",
    "    comm.Gatherv(y_test_pre_list,y_test_pre_l, root=0)\n",
    "    if rank == 0:\n",
    "        y_test_pre_list_ = np.transpose(y_test_pre_l.reshape(y_test_pre_l.shape[0]*y_test_pre_l.shape[1],y_test_pre_l.shape[2]))\n",
    "        # print(y_test_pre_list_.shape)\n",
    "        error_model_list_ = np.transpose(error_l.reshape(error_l.shape[0]*error_l.shape[1],error_l.shape[2]))\n",
    "        error_random = np.random.choice(np.array(error_model_list_).flatten(),(y_test_pre_list_.shape))\n",
    "        y_test_revise_list   = y_test_pre_list_ +   error_random\n",
    "        Left_list = np.quantile(np.transpose(y_test_revise_list),0.025,axis = 0)\n",
    "        print(Left_list.shape)\n",
    "        Right_list = np.quantile(np.transpose(y_test_revise_list),0.975,axis = 0)\n",
    "        print(Right_list.shape)\n",
    "        Bool_list = (y_test >= Left_list) & (y_test< Right_list)\n",
    "        \n",
    "        diff = Right_list-Left_list\n",
    "        results_10_1000 = pd.DataFrame([])\n",
    "        results_10_1000['Left_list'] = np.array(Left_list)\n",
    "        results_10_1000['Right_list'] = np.array(Right_list)\n",
    "        results_10_1000['Bool_list'] = np.array(Bool_list)\n",
    "        results_10_1000['width'] = np.array(diff)\n",
    "        results_10_1000['test'] = np.array(Test['fmv'].copy())\n",
    "        pd.DataFrame(results_10_1000).to_csv('./result/results_10_1000.csv',index = False)\n",
    "        print(f\"accuracy: {Bool_list.mean():.6f}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # name = MPI.Get_processor_name()\n",
    "    comm = MPI.COMM_WORLD\n",
    "    rank = comm.Get_rank()\n",
    "    size = comm.Get_size()\n",
    "    t = time.time()\n",
    "    Huber(comm,rank, size)\n",
    "    print((time.time()-t))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1676ad84-e83a-474c-bbd6-b049b49ef442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting RANSACR.py\n"
     ]
    }
   ],
   "source": [
    "%%file RANSACR.py\n",
    "#!/usr/bin/env python\n",
    "from mpi4py import MPI\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from sklearn.linear_model import HuberRegressor\n",
    "from sklearn.linear_model import RANSACRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import sys\n",
    "\n",
    "\n",
    "def RANSACR(comm,rank, size):\n",
    "    if rank == 0:\n",
    "        data = pd.read_csv(\"data.csv\")\n",
    "        split_rate = 0.9\n",
    "        Train = data.iloc[:int(data.shape[0]*split_rate),:]\n",
    "        Test = data.iloc[int(data.shape[0]*split_rate):,:]\n",
    "\n",
    "    else:\n",
    "        # data = None\n",
    "        Train = None\n",
    "        Test = None\n",
    "    # data = comm.bcast(data,root = 0)\n",
    "    Train = comm.bcast(Train,root = 0)\n",
    "    Test = comm.bcast(Test,root = 0)\n",
    "\n",
    "\n",
    "    y_test = Test['fmv']\n",
    "    X_test = Test.drop(['fmv'],axis = 1)\n",
    "    print(rank)\n",
    "    y_test_pre_list = []\n",
    "    error_model_list = []\n",
    "    for i in range(2):\n",
    "        Train_sample = Train.sample(frac = 1, replace = True)\n",
    "        y_train_sample = Train_sample['fmv']\n",
    "        X_train_sample = Train_sample.drop(['fmv'],axis = 1)\n",
    "\n",
    "        model = RANSACRegressor()\n",
    "        model.fit(X_train_sample,y_train_sample)\n",
    "\n",
    "        y_train_sample_pre = model.predict(X_train_sample)\n",
    "        error_model = y_train_sample-y_train_sample_pre\n",
    "        error_model_list.append(error_model)\n",
    "        y_test_pre = model.predict(X_test)\n",
    "        y_test_pre_list.append(y_test_pre)\n",
    "        print('The rank',rank,'iteration',i)\n",
    "    error_model_list = np.array(error_model_list)\n",
    "    y_test_pre_list = np.array(y_test_pre_list)\n",
    "    y_test_pre_l = np.empty((size,) + y_test_pre_list.shape)\n",
    "    error_l = np.empty((size,) + error_model_list.shape)\n",
    "    comm.Gatherv(error_model_list, error_l,root=0)\n",
    "    comm.Gatherv(y_test_pre_list,y_test_pre_l, root=0)\n",
    "    if rank == 0:\n",
    "        y_test_pre_list_ = np.transpose(y_test_pre_l.reshape(y_test_pre_l.shape[0]*y_test_pre_l.shape[1],y_test_pre_l.shape[2]))\n",
    "        print(y_test_pre_list_.shape)\n",
    "        error_model_list_ = np.transpose(error_l.reshape(error_l.shape[0]*error_l.shape[1],error_l.shape[2]))\n",
    "        error_random = np.random.choice(np.array(error_model_list_).flatten(),(y_test_pre_list_.shape))\n",
    "        y_test_revise_list   = y_test_pre_list_ +   error_random\n",
    "        Left_list = np.quantile(np.transpose(y_test_revise_list),0.025,axis = 0)\n",
    "        # print(Left_list.shape)\n",
    "        Right_list = np.quantile(np.transpose(y_test_revise_list),0.975,axis = 0)\n",
    "        # print(Right_list.shape)\n",
    "        Bool_list = (y_test >= Left_list) & (y_test< Right_list)\n",
    "\n",
    "        diff = Right_list-Left_list\n",
    "        results_10_1000 = pd.DataFrame([])\n",
    "        results_10_1000['Left_list'] = np.array(Left_list)\n",
    "        results_10_1000['Right_list'] = np.array(Right_list)\n",
    "        results_10_1000['Bool_list'] = np.array(Bool_list)\n",
    "        results_10_1000['width'] = np.array(diff)\n",
    "        results_10_1000['test'] = np.array(Test['fmv'].copy())\n",
    "        pd.DataFrame(results_10_1000).to_csv('./result/results_10_1000.csv',index = False)\n",
    "        print(f\"accuracy: {Bool_list.mean():.6f}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # name = MPI.Get_processor_name()\n",
    "    comm = MPI.COMM_WORLD\n",
    "    rank = comm.Get_rank()\n",
    "    size = comm.Get_size()\n",
    "    t = time.time()\n",
    "    RANSACR(comm,rank, size)\n",
    "    print(time.time()-t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05e7f973-ae8c-4f9b-8996-6c0f3d45cf6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting quantile.py\n"
     ]
    }
   ],
   "source": [
    "%%file quantile.py\n",
    "from mpi4py import MPI\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import sys\n",
    "import statsmodels.regression.quantile_regression as Q_reg\n",
    "\n",
    "\n",
    "def quantile(comm,rank, size):\n",
    "    if rank == 0:\n",
    "        data = pd.read_csv(\"data.csv\")\n",
    "        split_rate = 0.9\n",
    "        Train = data.iloc[:int(data.shape[0]*split_rate),:]\n",
    "        Test = data.iloc[int(data.shape[0]*split_rate):,:]\n",
    "\n",
    "    else:\n",
    "        # data = None\n",
    "        Train = None\n",
    "        Test = None\n",
    "    # data = comm.bcast(data,root = 0)\n",
    "    Train = comm.bcast(Train,root = 0)\n",
    "    Test = comm.bcast(Test,root = 0)\n",
    "\n",
    "\n",
    "    y_test = Test['fmv']\n",
    "    X_test = Test.drop(['fmv'],axis = 1)\n",
    "    # print(rank)\n",
    "    y_test_pre_left = []\n",
    "    y_test_pre_right = []\n",
    "    for i in range(3):\n",
    "        print('The rank',rank,'iteration',i)\n",
    "        Train_sample = Train.sample(frac = 1, replace = True)\n",
    "        y_train_sample = Train_sample['fmv']\n",
    "        X_train_sample = Train_sample.drop(['fmv'],axis = 1)\n",
    "        Y_test_pred_left = Q_reg.QuantReg(y_train_sample, X_train_sample).fit(q=0.025).predict(X_test)\n",
    "        Y_test_pred_right = Q_reg.QuantReg(y_train_sample, X_train_sample).fit(q=0.975).predict(X_test)\n",
    "        y_test_pre_left.append(Y_test_pred_left)\n",
    "        y_test_pre_right.append(Y_test_pred_right)\n",
    "        \n",
    "\n",
    "    y_test_pre_left = np.array(y_test_pre_left)\n",
    "    y_test_pre_l = np.empty((size,) +y_test_pre_left.shape)\n",
    "    y_test_pre_right = np.array(y_test_pre_right)\n",
    "    y_test_pre_r = np.empty((size,) +y_test_pre_right.shape)\n",
    "    comm.Gatherv(y_test_pre_left, y_test_pre_l,root=0)\n",
    "    comm.Gatherv(y_test_pre_right,y_test_pre_r, root=0)\n",
    "    if rank == 0:\n",
    "        y_test_pre_l_list = np.transpose(y_test_pre_l.reshape(y_test_pre_l.shape[0]*y_test_pre_l.shape[1],y_test_pre_l.shape[2]))\n",
    "        y_test_pre_r_list = np.transpose(y_test_pre_r.reshape(y_test_pre_r.shape[0]*y_test_pre_r.shape[1],y_test_pre_r.shape[2]))\n",
    "        Left_list = np.quantile(np.transpose(y_test_pre_l_list),0.5,axis = 0)\n",
    "        Right_list = np.quantile(np.transpose(y_test_pre_r_list),0.5,axis = 0)\n",
    "        Bool_list = (y_test >= Left_list) & (y_test< Right_list)\n",
    "        diff = Right_list-Left_list\n",
    "        results_10_1000 = pd.DataFrame([])\n",
    "        results_10_1000['Left_list'] = np.array(Left_list)\n",
    "        results_10_1000['Right_list'] = np.array(Right_list)\n",
    "        results_10_1000['Bool_list'] = np.array(Bool_list)\n",
    "        results_10_1000['width'] = np.array(diff)\n",
    "        results_10_1000['test'] = np.array(Test['fmv'].copy())\n",
    "        pd.DataFrame(results_10_1000).to_csv('./result/results_10_1000.csv',index = False)\n",
    "        print(f\"accuracy: {Bool_list.mean():.6f}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # name = MPI.Get_processor_name()\n",
    "    comm = MPI.COMM_WORLD\n",
    "    rank = comm.Get_rank()\n",
    "    size = comm.Get_size()\n",
    "    t = time.time()\n",
    "    quantile(comm,rank, size)\n",
    "    print(time.time()-t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b30fb00b-268a-4a5e-8193-a3553401d94e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting GBoost.py\n"
     ]
    }
   ],
   "source": [
    "%%file GBoost.py\n",
    "#!/usr/bin/env python\n",
    "from mpi4py import MPI\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from sklearn.linear_model import HuberRegressor\n",
    "# from sklearn.linear_model import RANSACRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import sys\n",
    "\n",
    "\n",
    "def GBoost(comm,rank, size):\n",
    "    if rank == 0:\n",
    "        data = pd.read_csv(\"data.csv\")\n",
    "        split_rate = 0.9\n",
    "        Train = data.iloc[:int(data.shape[0]*split_rate),:]\n",
    "        Test = data.iloc[int(data.shape[0]*split_rate):,:]\n",
    "\n",
    "    else:\n",
    "        # data = None\n",
    "        Train = None\n",
    "        Test = None\n",
    "    # data = comm.bcast(data,root = 0)\n",
    "    Train = comm.bcast(Train,root = 0)\n",
    "    Test = comm.bcast(Test,root = 0)\n",
    "\n",
    "\n",
    "    y_test = Test['fmv']\n",
    "    X_test = Test.drop(['fmv'],axis = 1)\n",
    "    print(rank)\n",
    "    y_test_pre_list = []\n",
    "    error_model_list = []\n",
    "    for i in range(2):\n",
    "        Train_sample = Train.sample(frac = 1, replace = True)\n",
    "        y_train_sample = Train_sample['fmv']\n",
    "        X_train_sample = Train_sample.drop(['fmv'],axis = 1)\n",
    "\n",
    "        model = GradientBoostingRegressor()\n",
    "        model.fit(X_train_sample,y_train_sample)\n",
    "        y_train_sample_pre = model.predict(X_train_sample)\n",
    "        error_model = y_train_sample-y_train_sample_pre\n",
    "        error_model_list.append(error_model)\n",
    "        y_test_pre = model.predict(X_test)\n",
    "        y_test_pre_list.append(y_test_pre)\n",
    "        print('The rank',rank,'iteration',i)\n",
    "    error_model_list = np.array(error_model_list)\n",
    "    y_test_pre_list = np.array(y_test_pre_list)\n",
    "    y_test_pre_l = np.empty((size,) + y_test_pre_list.shape)\n",
    "    error_l = np.empty((size,) + error_model_list.shape)\n",
    "    comm.Gatherv(error_model_list, error_l,root=0)\n",
    "    comm.Gatherv(y_test_pre_list,y_test_pre_l, root=0)\n",
    "    if rank == 0:\n",
    "        y_test_pre_list_ = np.transpose(y_test_pre_l.reshape(y_test_pre_l.shape[0]*y_test_pre_l.shape[1],y_test_pre_l.shape[2]))\n",
    "        print(y_test_pre_list_.shape)\n",
    "        error_model_list_ = np.transpose(error_l.reshape(error_l.shape[0]*error_l.shape[1],error_l.shape[2]))\n",
    "        error_random = np.random.choice(np.array(error_model_list_).flatten(),(y_test_pre_list_.shape))\n",
    "        y_test_revise_list   = y_test_pre_list_ +   error_random\n",
    "        Left_list = np.quantile(np.transpose(y_test_revise_list),0.025,axis = 0)\n",
    "        # print(Left_list.shape)\n",
    "        Right_list = np.quantile(np.transpose(y_test_revise_list),0.975,axis = 0)\n",
    "        # print(Right_list.shape)\n",
    "        Bool_list = (y_test >= Left_list) & (y_test< Right_list)\n",
    "\n",
    "        diff = Right_list-Left_list\n",
    "        results_10_1000 = pd.DataFrame([])\n",
    "        results_10_1000['Left_list'] = np.array(Left_list)\n",
    "        results_10_1000['Right_list'] = np.array(Right_list)\n",
    "        results_10_1000['Bool_list'] = np.array(Bool_list)\n",
    "        results_10_1000['width'] = np.array(diff)\n",
    "        results_10_1000['test'] = np.array(Test['fmv'].copy())\n",
    "        pd.DataFrame(results_10_1000).to_csv('./result/results_10_1000.csv',index = False)\n",
    "        print(f\"accuracy: {Bool_list.mean():.6f}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # name = MPI.Get_processor_name()\n",
    "    comm = MPI.COMM_WORLD\n",
    "    rank = comm.Get_rank()\n",
    "    size = comm.Get_size()\n",
    "    t = time.time()\n",
    "    GBoost(comm,rank, size)\n",
    "    print(time.time()-t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c02b507-94fb-482c-8597-652bf495f235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# analysis the data in 10%\n",
    "def readfile(modelname,splitrate,resample):\n",
    "    path = \"./\" + modelname + \"/result/\"\n",
    "    return pd.read_csv(path + \"results_\" + str(splitrate)+\"_\"+str(resample)+\".csv\")\n",
    "\n",
    "def readata(rate,iteration,default = False):\n",
    "    df_Huber = readfile(\"Huber\",rate,iteration)\n",
    "    df_RANSAC = readfile(\"RANSAC\",rate,iteration)\n",
    "    df_OLS = readfile(\"OLS\",rate,iteration)\n",
    "    df_quantile = readfile(\"quantile\",rate,iteration)\n",
    "    df_GradientBoost = readfile(\"GradientBoost\",rate,iteration)\n",
    "    return df_OLS,df_Huber,df_RANSAC,df_quantile,df_GradientBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ac1c7b6-8fd2-4a5b-97cf-35e22168f556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# difference test\n",
    "# rate = 10\n",
    "from scipy.stats import tukey_hsd\n",
    "rate_list = [10,20,30]\n",
    "itera = [1000,2000,3000,5000]\n",
    "letter = [\"(A)\",\"(B)\",\"(C)\",\"(D)\"]\n",
    "for rate in rate_list:\n",
    "    h = 0\n",
    "    # fig, ax = plt.subplots(2, 2,figsize=(10,8))\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            df_OLS,df_Huber,df_RANSAC,df_quantile,df_GradientBoost = readata(rate,itera[h])\n",
    "            # ax[i,j].tick_params(axis='both', which='major', labelsize=7)\n",
    "            # ax[i,j].tick_params(axis='both', which='minor', labelsize=7)\n",
    "            # ax[i,j].boxplot([df_OLS['width'],df_Huber['width'], df_RANSAC['width'],df_quantile['width'],df_GradientBoost['width']])\n",
    "            # ax[i,j].set_xticklabels([\"OLS\",\"Huber\", \"RANSAC\",\"quantile\",\"Gradient Boost\"]) \n",
    "            # ax[i,j].set_xlabel(\"{} R = {}\".format(letter[h],itera[h]))\n",
    "            \n",
    "            res = tukey_hsd(df_OLS['width'],df_Huber['width'], df_RANSAC['width'],df_quantile['width'],df_GradientBoost['width'])\n",
    "            # print(\"rate {}; iteration{}\".format(rate,itera[h]))\n",
    "            # print(res)\n",
    "            h = h+1\n",
    "    # plt.title(\"Split Rate = {}%\".format(rate))\n",
    "    # plt.savefig('./figure/rate_{}.png'.format(rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0c120e1-6a4d-413c-977b-d02cac8255f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getdensity(model,kde_x):\n",
    "    density = stats.gaussian_kde(model)\n",
    "    return density(kde_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4b0a644-17a3-4f26-a8d0-d23f415631fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_list = [10,20,30]\n",
    "itera = [1000,2000,3000,5000]\n",
    "letter = [\"(A)\",\"(B)\",\"(C)\",\"(D)\"]\n",
    "# noise = readfile(\"OLS\",10,1000)['width']\n",
    "# density = stats.gaussian_kde(noise)\n",
    "kde_x = np.linspace(-500, 1300, 1000)\n",
    "side = 'Left_list'\n",
    "for rate in rate_list:\n",
    "    h = 0\n",
    "    # fig, ax = plt.subplots(2, 2,figsize=(10,8))\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            df_OLS,df_Huber,df_RANSAC,df_quantile,df_GradientBoost = readata(rate,itera[h])\n",
    "            # ax[i,j].tick_params(axis='both', which='major', labelsize=7)\n",
    "            # ax[i,j].tick_params(axis='both', which='minor', labelsize=7)\n",
    "            # ax[i,j].plot(kde_x,getdensity(df_OLS[side],kde_x),label = \"OLS\")\n",
    "            # ax[i,j].plot(kde_x,getdensity(df_Huber[side],kde_x),label = \"Huber\")\n",
    "            # ax[i,j].plot(kde_x,getdensity(df_RANSAC[side],kde_x),label = \"RANSAC\")\n",
    "            # ax[i,j].plot(kde_x,getdensity(df_quantile[side],kde_x),label = \"quantile\")\n",
    "            # ax[i,j].plot(kde_x,getdensity(df_GradientBoost[side],kde_x),label = \"Gradient Boost\")\n",
    "            # ax[i,j].set_xlabel(\"{} R = {}\".format(letter[h],itera[h]))\n",
    "            # ax[i,j].legend()\n",
    "            res = tukey_hsd(df_OLS[side],df_Huber[side ], df_RANSAC[side ],df_quantile[side ],df_GradientBoost[side])\n",
    "            # print(res)\n",
    "            h = h+1\n",
    "    # plt.savefig('./figure/lefthist_rate_{}.png'.format(rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "afe2201e-589a-4a35-b8ea-e10538721075",
   "metadata": {},
   "outputs": [],
   "source": [
    "side = 'Right_list'\n",
    "rate_list = [10,20,30]\n",
    "itera = [1000,2000,3000,5000]\n",
    "letter = [\"(A)\",\"(B)\",\"(C)\",\"(D)\"]\n",
    "kde_x = np.linspace(-200, 1500, 1000)\n",
    "for rate in rate_list:\n",
    "    h = 0\n",
    "    # fig, ax = plt.subplots(2, 2,figsize=(10,8))\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            df_OLS,df_Huber,df_RANSAC,df_quantile,df_GradientBoost = readata(rate,itera[h])\n",
    "            # ax[i,j].tick_params(axis='both', which='major', labelsize=7)\n",
    "            # ax[i,j].tick_params(axis='both', which='minor', labelsize=7)\n",
    "            # ax[i,j].plot(kde_x,getdensity(df_OLS[side],kde_x ),label = \"OLS\")\n",
    "            # ax[i,j].plot(kde_x,getdensity(df_Huber[side],kde_x ),label = \"Huber\")\n",
    "            # ax[i,j].plot(kde_x,getdensity(df_RANSAC[side],kde_x ),label = \"RANSAC\")\n",
    "            # ax[i,j].plot(kde_x,getdensity(df_quantile[side],kde_x ),label = \"quantile\")\n",
    "            # ax[i,j].plot(kde_x,getdensity(df_GradientBoost[side],kde_x ),label = \"Gradient Boost\")\n",
    "            # ax[i,j].set_xlabel(\"{} R = {}\".format(letter[h],itera[h]))\n",
    "            res = tukey_hsd(df_OLS[side ],df_Huber[side ], df_RANSAC[side ],df_quantile[side ],df_GradientBoost[side ])\n",
    "            # print(res)\n",
    "            # ax[i,j].legend()\n",
    "            h = h+1\n",
    "    # plt.savefig('./figure/righthist_rate_{}.png'.format(rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6495ba-10c4-4dd9-9615-d0ebc490754c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
